# 操作系统

内核特征：并发、共享、虚拟、异步

内核态和用户态是操作系统中的两种运行模式。

**内核态**（Kernel Mode）：在内核态下，CPU可以执行所有的指令和访问**所有的硬件资源**。这种模 式下的操作具有更高的权限，主要用于操作系统内核的运行。 

**用户态**（User Mode）：在用户态下，CPU只能执行**部分指令集**，无法直接访问硬件资源。这种模 式下的操作权限较低，主要用于运行用户程序。 

内核态的底层操作主要包括：内存管理、进程管理、设备驱动程序控制、系统调用等。

分为内核态和用户态的原因主要有以下几点： 

1、安全性：通过对权限的划分，用户程序无法直接访问硬件资源，从而避免了恶意程序对系统资源 的破坏。

2、稳定性：用户态程序出现问题时，不会影响到整个系统，避免了程序故障导致系统崩溃的风险。

3、隔离性：内核态和用户态的划分使得操作系统内核与用户程序之间有了明确的边界，有利于系统 的模块化和维护。 

# 中断、异常和系统调用

![os1](C:\Users\25798\OneDrive\Notes\image\os1.png)

在计算机运行中，操作系统内核是**被信任**的第三方，可以执行特权指令。

中断：来自**外部硬件设备**的处理请求

异常：**非法指令**或者其他原因导致当前**指令执行失败**(如内存出错)后的**处理请求**

系统调用：应用程序**主动**向操作系统发出的**服务请求**

中断机制：1、现场保存 2、中断服务处理 3、清除中断标记 4、现场恢复

系统调用接口：通常由高级语言编写（C或者C++），**程序访问**通常是通过高层次的API接口而不是直接进行系统调用。每个系统调用对应一个系统调用号。系统调用接口调用**内核态**中的**系统调用功能**实现，应用系统调用时需要进行**堆栈转换和特权级的转换**，由用户态转为内核态。

由用户态转为内核态的开销：

1、引导机制转变 2、堆栈切换 3、地址空间的映射

硬件中断服务例程可被打断，即**中断可以嵌套**。**异常**服务例程可能**出现中断**，异常也可**嵌套**。

# 内存管理

通过CPU的存储管理单元(MMU)，处理CPU存储访问请求。

1、抽象 物理地址空间映射成逻辑地址空间

2、保护 保护物理地址空间不会错乱

3、共享 多进程相同的数据内容可以访问相同内存区域

4、虚拟化 可以将外存虚拟化成内存，扩大地址空间

内存管理方式：重定位、分段、分页、虚拟存储，与计算机存储架构紧耦合

## 地址空间

物理地址空间 — 硬件支持的地址空间

逻辑地址空间 — 在**CPU**运行的进程看到的地址

CPU提供逻辑地址 -> 操作系统判断**偏移量是否小于段长度** -> 偏移量加上段基址得到物理地址

## 连续内存分配

**连续内存分配**，会产生**内存碎片**。外部碎片：分配单元之间的空间，内部碎片：未取整部分的空间。

**动态分区分配**

程序被加载执行时，分配一个**进程**指定大小可变的**地址连续**的分区(块、内存块)。

动态分区分配策略：最先匹配、最佳匹配、最差匹配

最先匹配：按**地址顺序**排列，匹配**第一个**大于等于需求的空闲空间。分配大块空间时较慢。

最佳匹配：按**分区大小**排列，匹配**大于等于**需求的**最小**的那个空闲空间。外部碎片产生小，但是会产生很多无用的小碎片。

最差匹配：按**分区大小**排列，匹配**最大**的空闲空间。查询速度最快，小碎片少，但是会破坏大的分区。

释放分区时，检查是否可与临近的空闲分区合并。

### 碎片整理

通过调整合并进程占用的分区位置来减少或避免分区碎片。需要所有的应用程序**可动态重定位**。

分区对换(早期操作系统)：通过**抢占并回收**处于等待状态进程的分区，以增大可用内存空间。

### 伙伴系统

整个可分配的分区大小必须为2的幂。

空闲块按大小和起始地址组织成**二维数组**。由小到大在空闲块数组中找**最小**的可用空闲块，当可分配区域大于需求空间的两倍，则进行**分半**继续当前判断。

把释放的块放入空闲块数组，合并满足合并条件的空闲块。地址相邻，大小相同，且起始块为对应分半的起始块的两块空闲空间才可以合并。

外部碎片少，利用率高，但是内部碎片会增大。

## 非连续地址分配

提高内存利用效率和管理灵活性，允许一个程序的使用**非连续的物理地址空间**，允许共享代码与数据，支持动态加载和动态链接。

非连续分配的**硬件辅助机制**：段式存储管理、页式存储管理

### 段式存储管理

进程的**段地址空间**由多个段组成，主代码段、堆栈段(stack)、子模块代码段等，可以更细粒度和灵活的**分离与共享**。将逻辑地址转换为几段不连续的结构，段之间不通过偏移量进行访问，从而物理地址可以**分段**进行分配空间。

段表示访问方式和存储数据等属性相同的一段地址空间。

### 页式存储管理

**页帧**（帧、物理页面）

把**物理地址**空间划分为**大小相同**的基本分配单位，大小为2的n次幂。由**帧号**和**帧内偏移**表示。

**页面**（页、逻辑页面）

把**逻辑地址**空间也划分为**相同大小**的基本分配单位，大小必须与帧是相同的。页内偏移 = 帧内偏移，页号大小 ≠ 帧号大小，

通过**页表**完成逻辑地址到物理地址的转换，**页表**保存了逻辑地址和物理地址之间的**映射关系**。

1、逻辑地址中的页号是连续的

2、物理地址中的帧号是不连续的

3、**不是**所有的页都有对应的帧

### 页表

每个进程都有一个页表，每个页面对应一个页表项，随进程运行状态而动态变化，页表基址寄存器中存储了页表的内容。

访问一个内存单元需要**2次内存访问**，1、获取页表项 2、访问数据

页表可能**非常大**。

**快表**：**CPU中缓存**近期访问的页表项，减少内存访问的次数。

**多级页表**：通过**间接引用**将页号分成k级，建立**页表“树”**，减少每级页表的长度。但对于大地址空间(64-bits)系统，多级页表变得繁琐。

**反置页表**：页表与**物理地址**空间的大小相对应，每个**帧**与一个**页寄存器**关联，存储对应的页号。页表大小相对于物理内存而言很小，与逻辑地址空间大小无关。但是需要**搜索**逻辑地址中的页号。基于**Hash映射值**查找对应页表项中的**帧号**。

### 段页式存储管理

在段式存储管理基础上，给**每个段加一级页表**。通过指向相同的**页表基址**，实现**进程间的段共享**。

# 虚拟存储

## 覆盖技术

在较小的可用内存中运行较大的程序。

依据程序**逻辑结构**，将程序划分为若干**功能相对独立**的模块；将不会同时执行的模块**共享同一块内存**区域。

1、常用功能的代码和数据常驻内存

2、不常用功能放在其他程序模块中,只在需要用到时装入内存

3、不存在**调用关系**的模块可相互覆盖，共用同一块内存区域

缺点：1、增加编程困难 2、增加执行时间

## 交换技术

增加正在运行或需要运行的程序的内存。

只当内存空间不够使，可将暂时不能运行的程序放到外存，将外存中某进程的地址空间采用**动态地址映射**的方法**重定位**读入到内存。

<img src="C:\Users\25798\OneDrive\Notes\image\os2.png" alt="os1" style="zoom:67%;" />

## 局部性原理

**时间局部性**：一条指令的一次执行和下次执行，一个数据的一次访问和下次访问都集中在一个较短时期内。

**空间局部性**：当前指令和邻近的几条指令，当前访问的数据和邻近的几个数据都集中在一个较小区域内。

**分支局部性**：一条跳转指令的两次执行，很可能跳到相同的内存位置

局部性越高，程序性能就越高。

## 虚拟存储原理

将**不常用**的部分内存块暂存到**外存**。

1、只将**当前指令**执行需要的部分页面或段**装入内存**

2、指令执行中需要的指令或数据不在内存（称为缺页或缺段）时，处理器通知操作系统将相应的页面或段调入内存

3、操作系统将**内存**中暂时不用的页面或段保存到**外存**

1、**不连续性**，物理内存分配非连续，虚拟地址空间使用非连续

2、**大用户空间**，提供给用户的虚拟内存可大于实际的物理内存

3、**部分交换**，虚拟存储只对部分虚拟地址空间进行调入和调出

## 虚拟页式存储管理

在页式存储管理的基础上，增加请求调页和页面置换。

1、当用户程序要装载到内存运行时，只装入部分页面，就启动程序运行

2、进程在运行中发现有需要的代码或数据不在内存时，则向系统发出**缺页异常请求**

3、操作系统在处理缺页异常时，将外存中相应的页面调入内存，使得进程能继续运行

## 缺页异常

1、加载数据，查询页表项失败

2、操作系统查询出外存中的页面

3、页面换入内存

4、修改页表中的页表项

5、重新执行指令进行数据加载

## 页面置换算法

当出现缺页异常，需调入新页面而内存已满时，置换算法**选择被置换的物理页面**。算法**更少的缺页**, 则拥有更好的性能。

**页面锁定**：

1、描述必须常驻内存的逻辑页面

2、操作系统的关键部分

3、要求响应速度的代码和数据

4、页表中的锁定标志位(lock bit)

**局部页面置换**算法：

1、置换页面的选择范围仅限于当前进程占用的物理页面内

2、最优算法、先进先出算法、最近最久未使用算法

3、时钟算法、最不常用算法

**全局页面置换**算法：

1、置换页面的选择范围是所有可换出的物理页面

2、工作集算法、缺页率算法

3、为进程分配**可变数目**的物理页面，进程在不同阶段的内存需求是变化的。

**最优算法**

缺页时，计算内存中每个逻辑页面的下一次访问时间，置换在**未来最长时间不访问**的页面。实际系统中**无法实现**，作为置换算法的**性能评价依据**。

**先进先出算法**FIFO

维护一个记录所有位于内存中的逻辑页面链表，链表元素**按驻留内存的时间排序**，选择**在内存驻留时间最长**的页面进行置换。实现简单，性能较差，容易产生Belady现象。

**最近最久未使用算法**LRU

缺页时，计算内存中每个逻辑页面的**上一次访问时间**，选择上一次使用到当前时间最长的页面。

系统维护一个按最近一次访问时间排序的页面链表，访问内存时，找到相应页面，并把它移到链表之首，置换链表尾节点的页面。开销比较大。可退化成FIFO。

**时钟页面置换算法**Clock

时钟算法是LRU和FIFO的折中。在页表项中增加访问位，描述页面在过去一段时间的内访问情况，指针指向最先调入的页面，从指针处开始顺序查找未被访问的页面进行置换。在页面中增加**修改位**，并在访问时跳过修改的页面。

**最不常用算法**LFU

每个页面设置一个**访问计数**，缺页时，置换计数最小的页面。计数需要定期右移。

### Belady现象

采用置换算法时，可能出现分配的物理页面数增加，缺页次数反而升高的**异常现象**。原因是算法的置换特征与进程访问内存的动态**特征矛盾**。

存在此现象：FIFO算法

不存在此现象：LRU算法

**工作集置换算法**

换出不在工作集中的页面，1、维护窗口内的访存页面链表，2、访存时，换出不在工作集的页面；更新访存链表，3、缺页时，换入页面；更新访存链表

**缺页率算法**

缺页次数 / 内存访问次数，通过调节常驻集大小，使每个进程的缺页率保持在一个合理的范围内。

### 抖动和负载控制

<img src="C:\Users\25798\OneDrive\Notes\image\os3.png" alt="os1" style="zoom:67%;" />

随着驻留内存的进程数目增加，分配给每个进程的物理页面数不断减小，缺页率不断上升。通过调节并发进程数（MPL）来进行系统负载控制。

# 进程和线程



# 处理机调度



# 锁



# 文件系统



# I/O